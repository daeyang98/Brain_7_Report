{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard modules\r\n",
    "from typing import Dict, NamedTuple, List, Tuple\r\n",
    "import os\r\n",
    "import pickle\r\n",
    "import glob\r\n",
    "\r\n",
    "# External modules\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "import yaml\r\n",
    "\r\n",
    "# Models\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn import svm\r\n",
    "\r\n",
    "# Internal modules\r\n",
    "from aliases import *\r\n",
    "from models import *\r\n",
    "from snippet_accuracy import calculate_snippet_accuracy\r\n",
    "from streaming_accuracy import calculate_streaming_accuracy, DataSample, load_data_samples\r\n",
    "from train_models import Snippets, load_snippet_files, process_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFICATION_FILE: FilePath = \"recordings/Actual Event Times.csv\"\r\n",
    "df: pd.DataFrame = pd.read_csv(CLASSIFICATION_FILE)\r\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data: List[DataSample] = load_data_samples(CLASSIFICATION_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SpikerBox parameters\r\n",
    "CONFIG_PATH: FilePath = \"settings/spiker_box.srconfig\"\r\n",
    "with open(CONFIG_PATH, \"r\") as config_file:\r\n",
    "    config_data: Dict = yaml.safe_load(config_file)\r\n",
    "    # SpikerBox arguments\r\n",
    "    buffer_time: float = float(config_data[\"buffer_time\"])\r\n",
    "    update_factor: float = float(config_data[\"update_factor\"])\r\n",
    "    wait_time: float = float(config_data[\"wait_time\"])\r\n",
    "    num_samples: int = int(config_data[\"num_samples\"])\r\n",
    "    quality_factor: float = float(config_data[\"quality_factor\"])\r\n",
    "    # Modified simple classifier parameters\r\n",
    "    m_event_threshold: int = int(config_data[\"classifier\"][\"MSC\"][\"event_threshold\"])\r\n",
    "    positive_amplitude: float = float(config_data[\"classifier\"][\"MSC\"][\"positive_amplitude\"])\r\n",
    "    negative_amplitude: float = float(config_data[\"classifier\"][\"MSC\"][\"negative_amplitude\"])\r\n",
    "    spacing: float = float(config_data[\"classifier\"][\"MSC\"][\"spacing\"])\r\n",
    "    # Simple classifier parameters\r\n",
    "    s_event_threshold: int = int(config_data[\"classifier\"][\"USC\"][\"event_threshold\"])\r\n",
    "    # Catch22 model paths\r\n",
    "    knn_path: FilePath = config_data[\"classifier\"][\"KNN\"][\"file_path\"]\r\n",
    "    rfc_path: FilePath = config_data[\"classifier\"][\"RFC\"][\"file_path\"]\r\n",
    "    svc_path: FilePath = config_data[\"classifier\"][\"SVC\"][\"file_path\"]\r\n",
    "\r\n",
    "# Snippets folder\r\n",
    "SNIPPET_FOLDER: FilePath = \"snippets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming Accuracies\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_simplemodel_streaming(model: ModelBase, kfold: KFold) -> List[float]:\r\n",
    "    # Initialise model accuracy list\r\n",
    "    accuracies: List[float] = []\r\n",
    "    # Evaluate k-fold accuracy\r\n",
    "    for count, (train, test) in enumerate(kfold.split(data)):\r\n",
    "        _train_data: List[DataSample] = [sample for idx, sample in enumerate(data) if idx in train]\r\n",
    "        test_data: List[DataSample] = [sample for idx, sample in enumerate(data) if idx in test]\r\n",
    "\r\n",
    "        # Get accuracy\r\n",
    "        trial_accuracy: float = calculate_streaming_accuracy(\r\n",
    "            test_data,\r\n",
    "            model,\r\n",
    "            True,\r\n",
    "            buffer_time,\r\n",
    "            update_factor,\r\n",
    "            wait_time,\r\n",
    "            num_samples,\r\n",
    "            quality_factor,\r\n",
    "        )\r\n",
    "        # Append\r\n",
    "        accuracies.append(trial_accuracy)\r\n",
    "        # Iterate\r\n",
    "        print(f\"Finished trial {count+1}\")\r\n",
    "        count += 1\r\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_catch22model(untrained_model: SupportsPredict, training_files: List[FilePath]) -> Catch22Model:\r\n",
    "    train_data: List[FilePath] = []\r\n",
    "    for file_path in training_files:\r\n",
    "        _, tail = os.path.split(file_path)\r\n",
    "        tail = tail.rstrip(\".npy\")\r\n",
    "        for train_path in glob.glob(f\"{SNIPPET_FOLDER}/{tail}_*\"):\r\n",
    "            train_data.append(train_path)\r\n",
    "    snippets: Snippets = load_snippet_files({}, train_data)\r\n",
    "    snippet_data, labels = process_snippets(snippets, num_samples)\r\n",
    "    untrained_model.fit(snippet_data, labels)\r\n",
    "    return Catch22Model(untrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_catch22model_streaming(data: List[DataSample], kfold: KFold, model_type: ModelType) -> List[float]:\r\n",
    "    accuracies: List[float] = []\r\n",
    "    # Evaluate k-fold accuracy\r\n",
    "    for count, (train, test) in enumerate(kfold.split(data)):\r\n",
    "        # Train model\r\n",
    "        training_files: List[FilePath] = [sample.file_name for idx, sample in enumerate(data) if idx in train]\r\n",
    "        untrained_model: SupportsPredict;\r\n",
    "        if model_type == ModelType.KNN:\r\n",
    "            untrained_model = KNeighborsClassifier(n_neighbors=5)\r\n",
    "        elif model_type == ModelType.RFC:\r\n",
    "            untrained_model = RandomForestClassifier(n_estimators=100)\r\n",
    "        elif model_type == ModelType.SVC:\r\n",
    "            untrained_model = svm.SVC()\r\n",
    "        model: Catch22Model = train_catch22model(untrained_model, training_files)\r\n",
    "        # Test data\r\n",
    "        test_data: List[DataSample] = [sample for idx, sample in enumerate(data) if idx in test]\r\n",
    "\r\n",
    "        # Get accuracy\r\n",
    "        trial_accuracy: float = calculate_streaming_accuracy(\r\n",
    "            test_data,\r\n",
    "            model,\r\n",
    "            True,\r\n",
    "            buffer_time,\r\n",
    "            update_factor,\r\n",
    "            wait_time,\r\n",
    "            num_samples,\r\n",
    "            quality_factor,\r\n",
    "        )\r\n",
    "        # Append\r\n",
    "        accuracies.append(trial_accuracy)\r\n",
    "        # Iterate\r\n",
    "        print(f\"Finished trial {count+1}\")\r\n",
    "        count += 1\r\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_accuracies: Dict[ModelType, List[float]] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified simple classifier\r\n",
    "# Model parameters\r\n",
    "model_parameters: List[float] = [\r\n",
    "    m_event_threshold,\r\n",
    "    positive_amplitude,\r\n",
    "    negative_amplitude,\r\n",
    "    spacing,\r\n",
    "]\r\n",
    "# Initialise model\r\n",
    "model: ModelBase = ModifiedModel(*model_parameters)\r\n",
    "# Initialise model accuracy list\r\n",
    "accuracies: List[float] = test_simplemodel_streaming(model, kfold)\r\n",
    "# Set new value\r\n",
    "streaming_accuracies[ModelType.MSC] = accuracies\r\n",
    "print(np.median(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple classifier\r\n",
    "# Initialise model\r\n",
    "model: ModelBase = SimpleModel(s_event_threshold)\r\n",
    "# Initialise model accuracy list\r\n",
    "accuracies: List[float] = test_simplemodel_streaming(model, kfold)\r\n",
    "# Set new value\r\n",
    "streaming_accuracies[ModelType.USC] = accuracies\r\n",
    "print(np.median(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\r\n",
    "accuracies: List[float] = test_catch22model_streaming(data, kfold, ModelType.KNN)\r\n",
    "# Set new value\r\n",
    "streaming_accuracies[ModelType.KNN] = accuracies\r\n",
    "print(np.median(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFC\r\n",
    "accuracies: List[float] = test_catch22model_streaming(data, kfold, ModelType.RFC)\r\n",
    "# Set new value\r\n",
    "streaming_accuracies[ModelType.RFC] = accuracies\r\n",
    "print(np.median(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\r\n",
    "accuracies: List[float] = test_catch22model_streaming(data, kfold, ModelType.SVC)\r\n",
    "# Set new value\r\n",
    "streaming_accuracies[ModelType.SVC] = accuracies\r\n",
    "print(np.median(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIAGNOSTICS_FOLDER: FilePath = \"diagnostics\"\r\n",
    "if not os.path.isdir(DIAGNOSTICS_FOLDER):\r\n",
    "    os.mkdir(DIAGNOSTICS_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot comparing all the accuracies across models\r\n",
    "plt.boxplot(streaming_accuracies.values(), labels=[\"MSC\", \"USC\", \"KNN\", \"RFC\", \"SVC\"])\r\n",
    "plt.ylim(0, 1.1);\r\n",
    "plt.ylabel(\"Accuracy\")\r\n",
    "plt.title(\"10-fold cross validation streaming accuracies\")\r\n",
    "plt.savefig(f\"{DIAGNOSTICS_FOLDER}/streaming_boxplot.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_accuracies_cache: FilePath = f\"{DIAGNOSTICS_FOLDER}/streaming_accuracies.pickle\"\r\n",
    "if not os.path.isfile(streaming_accuracies_cache):\r\n",
    "    with open(streaming_accuracies_cache, \"wb\") as handle:\r\n",
    "        pickle.dump(streaming_accuracies, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(streaming_accuracies_cache):\r\n",
    "    with open(streaming_accuracies_cache, \"rb\") as handle:\r\n",
    "        accuracy_data = pickle.load(handle)\r\n",
    "        plt.boxplot(accuracy_data.values(), labels=[\"MSC\", \"USC\", \"KNN\", \"RFC\", \"SVC\"])\r\n",
    "        plt.ylim(0, 1.1);\r\n",
    "        plt.ylabel(\"Accuracy\")\r\n",
    "        plt.title(\"10-fold cross validation streaming accuracies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snippet Accuracies\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_simplemodel_snippet(model: ModelBase, kfold: KFold) -> List[float]:\r\n",
    "    # Initialise model accuracy list\r\n",
    "    accuracies: List[float] = []\r\n",
    "    # Evaluate k-fold accuracy\r\n",
    "    for count, (train, test) in enumerate(kfold.split(data)):\r\n",
    "        _training_data: List[DataSample] = [sample for idx, sample in enumerate(data) if idx in train]\r\n",
    "        test_files: List[DataSample] = [sample.file_name for idx, sample in enumerate(data) if idx in test]\r\n",
    "        test_data: List[FilePath] = []\r\n",
    "        for file_path in test_files:\r\n",
    "            _, tail = os.path.split(file_path)\r\n",
    "            tail = tail.rstrip(\".npy\")\r\n",
    "            for train_path in glob.glob(f\"{SNIPPET_FOLDER}/{tail}_*\"):\r\n",
    "                test_data.append(train_path)\r\n",
    "\r\n",
    "        # Get accuracy\r\n",
    "        trial_accuracy: float = calculate_snippet_accuracy(\r\n",
    "            model,\r\n",
    "            test_data,\r\n",
    "            num_samples,\r\n",
    "        )\r\n",
    "        # Append\r\n",
    "        accuracies.append(trial_accuracy)\r\n",
    "        # Iterate\r\n",
    "        print(f\"Finished trial {count+1}\")\r\n",
    "        count += 1\r\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_catch22model_snippets(data: List[DataSample], kfold: KFold, model_type: ModelType) -> List[float]:\r\n",
    "    accuracies: List[float] = []\r\n",
    "    # Evaluate k-fold accuracy\r\n",
    "    for count, (train, test) in enumerate(kfold.split(data)):\r\n",
    "        # Train model\r\n",
    "        training_files: List[FilePath] = [sample.file_name for idx, sample in enumerate(data) if idx in train]\r\n",
    "        untrained_model: SupportsPredict;\r\n",
    "        if model_type == ModelType.KNN:\r\n",
    "            untrained_model = KNeighborsClassifier(n_neighbors=5)\r\n",
    "        elif model_type == ModelType.RFC:\r\n",
    "            untrained_model = RandomForestClassifier(n_estimators=100)\r\n",
    "        elif model_type == ModelType.SVC:\r\n",
    "            untrained_model = svm.SVC()\r\n",
    "        model: Catch22Model = train_catch22model(untrained_model, training_files)\r\n",
    "        # Test data\r\n",
    "        test_files: List[DataSample] = [sample.file_name for idx, sample in enumerate(data) if idx in test]\r\n",
    "        test_data: List[FilePath] = []\r\n",
    "        for file_path in test_files:\r\n",
    "            _, tail = os.path.split(file_path)\r\n",
    "            tail = tail.rstrip(\".npy\")\r\n",
    "            for train_path in glob.glob(f\"{SNIPPET_FOLDER}/{tail}_*\"):\r\n",
    "                test_data.append(train_path)\r\n",
    "\r\n",
    "        # Get accuracy\r\n",
    "        trial_accuracy: float = calculate_snippet_accuracy(\r\n",
    "            model,\r\n",
    "            test_data,\r\n",
    "            num_samples,\r\n",
    "        )\r\n",
    "        # Append\r\n",
    "        accuracies.append(trial_accuracy)\r\n",
    "        # Iterate\r\n",
    "        print(f\"Finished trial {count+1}\")\r\n",
    "        count += 1\r\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet_accuracies: Dict[ModelType, List[float]] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified simple classifier\r\n",
    "# Model parameters\r\n",
    "model_parameters: List[float] = [\r\n",
    "    m_event_threshold,\r\n",
    "    positive_amplitude,\r\n",
    "    negative_amplitude,\r\n",
    "    spacing,\r\n",
    "]\r\n",
    "# Initialise model\r\n",
    "model: ModelBase = ModifiedModel(*model_parameters)\r\n",
    "# Initialise model accuracy list\r\n",
    "accuracies: List[float] = test_simplemodel_snippet(model, kfold)\r\n",
    "# Set new value\r\n",
    "snippet_accuracies[ModelType.MSC] = accuracies\r\n",
    "print(np.median(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple classifier\r\n",
    "# Initialise model\r\n",
    "model: ModelBase = SimpleModel(s_event_threshold)\r\n",
    "# Initialise model accuracy list\r\n",
    "accuracies: List[float] = test_simplemodel_snippet(model, kfold)\r\n",
    "# Set new value\r\n",
    "snippet_accuracies[ModelType.USC] = accuracies\r\n",
    "print(np.median(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\r\n",
    "accuracies: List[float] = test_catch22model_snippets(data, kfold, ModelType.KNN)\r\n",
    "# Set new value\r\n",
    "snippet_accuracies[ModelType.KNN] = accuracies\r\n",
    "print(np.median(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFC\r\n",
    "accuracies: List[float] = test_catch22model_snippets(data, kfold, ModelType.RFC)\r\n",
    "# Set new value\r\n",
    "snippet_accuracies[ModelType.RFC] = accuracies\r\n",
    "print(np.median(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\r\n",
    "accuracies: List[float] = test_catch22model_snippets(data, kfold, ModelType.SVC)\r\n",
    "# Set new value\r\n",
    "snippet_accuracies[ModelType.SVC] = accuracies\r\n",
    "print(np.median(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot comparing all the accuracies across models\r\n",
    "plt.boxplot(snippet_accuracies.values(), labels=[\"MSC\", \"USC\", \"KNN\", \"RFC\", \"SVC\"])\r\n",
    "plt.ylim(0, 1.1);\r\n",
    "plt.ylabel(\"Accuracy\")\r\n",
    "plt.title(\"10-fold cross validation snippet accuracies\")\r\n",
    "plt.savefig(f\"{DIAGNOSTICS_FOLDER}/snippet_boxplot.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet_accuracies_cache: FilePath = f\"{DIAGNOSTICS_FOLDER}/snippet_accuracies.pickle\"\r\n",
    "if not os.path.isfile(snippet_accuracies_cache):\r\n",
    "    with open(snippet_accuracies_cache, \"wb\") as handle:\r\n",
    "        pickle.dump(snippet_accuracies, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(snippet_accuracies_cache):\r\n",
    "    with open(snippet_accuracies_cache, \"rb\") as handle:\r\n",
    "        accuracy_data = pickle.load(handle)\r\n",
    "        plt.boxplot(accuracy_data.values(), labels=[\"MSC\", \"USC\", \"KNN\", \"RFC\", \"SVC\"])\r\n",
    "        plt.ylim(0, 1.1);\r\n",
    "        plt.ylabel(\"Accuracy\")\r\n",
    "        plt.title(\"10-fold cross validation snippet accuracies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54e01427aa8be7bec89e51c9856e65d365354790435ad568830a6719ba3e065c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('main_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}